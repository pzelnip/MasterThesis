\startchapter{Miscellaneous (or I haven't found a place for it yet)}
\label{chapter:misc}

\section{Outline of an experiment for evaluating the effectiveness of the Gem Cutter}

\begin{flushright}
\textit{...a scientist must also be absolutely like a child.  If he sees a thing, he must say that he sees it, whether it was what he thought he was going to see or not.  See first, think later, then test.  But always see first.  Otherwise you will only see what you were expecting.}
\\
Douglas Adams \cite{Adams84} \\
\end{flushright}

In Chapter \ref{chapter:Exp} we explored a qualitative evaluation of the Gem Cutter with a bias towards a pedagogical viewpoint.  However, a useful compliment to this would be to explore a more \emph{quantitative} evaluation of the environment.  In this section we will outline an experiment which could provide a meaningful empirical evaluation of the Gem Cutter.

\section{Avenues of Evaluation}

\cite{Kelso02} outlined an experiment for his VFPE in which he outlined two possible avenues of for empirical evaluation of the VFPE:

\begin{enumerate}
	\item Evaluating the general adequacy of the environment
	\item Investigating Visual Programming proper
\end{enumerate}

The first is focused on conducting experiments to evaluate the general adequacy of the programming environment.  Such experiments would focus on showing quantitatively that for programmers experienced with textual languages, that the visual environment is not significantly worse than the textual alternative.  That is, that the environment is ``feature-equivalent'' to a given textual environment.

The second is for the purpose of exploring the textual/visual division.  That is, experiments designed here would be for the purpose of identifying differences that are due solely to the respective modes of display and the programming environment tools.  This was the type of experiment that Kelso outlined for his VFPE.  This requires a textual environment which is roughly equivalent to the VFPE.  
Given that the VFPE from a semantics and abstract syntax viewpoint is very similar to Haskell, Kelso believed that an experiment comparing the two would reveal differences between the visual and textual forms of representation.  Given that the Gem Cutter truly is the visual representation of CAL code, it would seem that an experiment of this form with the Gem Cutter and CAL would be more telling of the differences between the visual and the textual.

In addition to these, we can foresee other avenues for empirical evaluation of the Gem Cutter, most notably that of the functional versus object-orientation.  There have already been studies which have explored the differences between functional programming and object-orientated programing (FIXME - references??), but they have all been based solely in the textual world.  Similar experiments using the Gem Cutter (a visual environment rooted in the functional paradigm) and one of the common object-orientated environments (such as Prograph, Alice, or Scratch) would be an interesting addition to the work exploring the difference between the two paradigms.

For our purposes as educators however, we are more interested about how effective the Gem Cutter can be as a learning tool for students.  As such, we shall identify an experiment which explores two other avenues of exploration.  The first is to assess if the Gem Cutter can meet a typical set of learning objectives (ie - ``Does the student learn the concept?''), and the second assesses the transfer of skill to another environment (ie - ``Can the student apply what he/she learned to a different language?'').

\section{Difficulties}

Assessing which of two competing methods of instruction is more effective seems at first glance to be a simple task.  Simply teach one subject with both methods and compare the results of the two approaches.  However, as outlined by McKeachie in \cite{teachingTips} there are some difficulties or ``hidden traps'' that arise in trying to evaluate two different approaches to instruction.

The first category of problems are methodological, 

From Teaching Tips, \cite{teachingTips}:

methodological problems:

\begin{itemize}
	\item Hawthorne effect - instructor enthusiasm can influence quality of instruction, students react differently when they know they are being taught by an experimental method -- necessitates evaluation over period of time
	\item Finding control group -- different classes have different makeups of students, some instructors are better than others (so if method is successful how much is the method and how much the instructor)
\end{itemize}

criterion problem - you want to ``know what each group learned that the other did not.  Thus a comparison of the lecture method with a discussion method based on a common final examination from a textbook does not really compare what the two groups of students learned in their different classes, but rather what they learned from reading the text.''  ''criterion measure should sample progress on \textit{all} goals, not just a small sample chosen for a particular method.''  Student motivation -- students are motivated to get good grades, and thus may compensate for poor instruction, thereby obfuscating research results.

\section{Preparation}


\section{Group Selection}


\section{Measurement}

\section{Misc Notes}

\cite{Bayliss09} in 3.7 talks about important points in assessing the use of games, which may be relevant to this experiment.