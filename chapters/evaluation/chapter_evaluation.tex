\startchapter{Evaluation of The Gem Cutter Environment}
\label{chapter:Exp}

\begin{flushright}
\textit{...a scientist must also be absolutely like a child.  If he sees a thing, he must say that he sees it, whether it was what he thought he was going to see or not.  See first, think later, then test.  But always see first.  Otherwise you will only see what you were expecting.}
\\
Douglas Adams \cite{Adams84} \\
\end{flushright}

\section{Applying the Cognitive Dimensions Framework to the Gem Cutter}

Apply cg framework to Gem Cutter....

languages which do not require variables to be declared before they are used.  For example in fixme reference, we three implementations of the well known quadratic equation, one in Java, one in Python, and the last in Gem Cutter.  The two textual versions contain the same error in both: the identifier ``disc'' is misspelled on its second use, and thus does not refer to the value desired (the discriminant).  However, in SML, because identifiers must be declared via a val-binding before they are used this error is caught at compile time, whereas in Python (which does not require variables be declared before use), this results in a runtime error the programmer must debug.  Thus one could argue that SML is less error-prone than Python.  However, the Gem Cutter version completely avoids the possibility of the error, as one cannot add an emitter gem unless there is already a corresponding collector gem on the tabletop.

Hidden dependencies -- gem A depends on gem B, so changes to B can break A.
Hidden dependencies -- diamond and line makes connections between gems much more visually apparent.
Premature Commitment -- problem of not being able to save an incomplete gem (commitment to order of creation)
Progressive Evaluation -- ability to evaluate any subexpression at any time by right-clicking and choosing ``run gem''

\section{Outline Of An Experiment For Evaluating The Effectiveness Of The Gem Cutter}

In the preceding section we explored a qualitative evaluation of the Gem Cutter with a bias toward a pedagogical viewpoint.  However, a useful compliment to this would be to explore a more \emph{quantitative} evaluation of the environment.  In this section we will outline an experiment which could provide a meaningful empirical evaluation of the Gem Cutter.

\subsection{Avenues of Evaluation}

\cite{Kelso02} outlined an experiment for his VFPE in which he outlined two possible avenues of for empirical evaluation of the VFPE:

\begin{enumerate}
	\item Evaluating the general adequacy of the environment
	\item Investigating Visual Programming proper
\end{enumerate}

The first is focused on conducting experiments to evaluate the general adequacy of the programming environment.  Such experiments would focus on showing quantitatively that for programmers experienced with textual languages, that the visual environment is not significantly worse than the textual alternative.  That is, that the environment is ``feature-equivalent'' to a given textual environment.

The second is for the purpose of exploring the textual/visual division.  That is, experiments designed here would be for the purpose of identifying differences that are due solely to the respective modes of display and the programming environment tools.  This was the type of experiment that Kelso outlined for his VFPE.  This requires a textual environment which is roughly equivalent to the VFPE.  
Given that the VFPE from a semantics and abstract syntax viewpoint is very similar to Haskell, Kelso believed that an experiment comparing the two would reveal differences between the visual and textual forms of representation.  Given that the Gem Cutter truly is the visual representation of CAL code, it would seem that an experiment of this form with the Gem Cutter and CAL would be more telling of the differences between the visual and the textual.

In addition to these, we can foresee other avenues for empirical evaluation of the Gem Cutter, most notably that of functional versus object-orientated programming.  There have already been studies which have explored the differences between the two paradigms (FIXME - references??), but they have largely been based solely in the textual world.  Similar experiments using the Gem Cutter (a visual environment rooted in the functional paradigm) and one of the common object-orientated environments (such as Prograph, Alice, or Scratch) would be an interesting addition to the work exploring the difference between the two paradigms.

For our purposes as educators however, we are more interested about how effective the Gem Cutter can be as a learning tool for students.  As such, we shall identify an experiment which explores two other avenues of exploration.  The first is to assess if the Gem Cutter can meet a typical set of learning objectives (ie - ``Does the student learn the concept?''), and the second assesses the transfer of skill to another environment (ie - ``Can the student apply what he/she learned to a different language?'').

\subsection{Difficulties}

Assessing which of two competing methods of instruction is more effective seems at first glance to be a simple task.  Simply teach one subject with both methods and compare the results of the two approaches.  However, as outlined by McKeachie in \cite{teachingTips} there are some difficulties or ``hidden traps'' that arise in trying to evaluate two different approaches to instruction.

The first category of problems are methodological, 

From Teaching Tips, \cite{teachingTips}:

methodological problems:

\begin{itemize}
	\item Hawthorne effect - instructor enthusiasm can influence quality of instruction, students react differently when they know they are being taught by an experimental method -- necessitates evaluation over period of time
	\item Finding control group -- different classes have different makeups of students, some instructors are better than others (so if method is successful how much is the method and how much the instructor)
\end{itemize}

criterion problem - you want to ``know what each group learned that the other did not.  Thus a comparison of the lecture method with a discussion method based on a common final examination from a textbook does not really compare what the two groups of students learned in their different classes, but rather what they learned from reading the text.''  ''criterion measure should sample progress on \textit{all} goals, not just a small sample chosen for a particular method.''  Student motivation -- students are motivated to get good grades, and thus may compensate for poor instruction, thereby obfuscating research results.

\subsection{Preparation}


\subsection{Group Selection}


\subsection{Measurement}

\section{Misc Notes}

\cite{Bayliss09} in 3.7 talks about important points in assessing the use of games, which may be relevant to this experiment.